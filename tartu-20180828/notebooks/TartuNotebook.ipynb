{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We begin with setting up the Data Access Component (DAC). The DAC is responsible for retrieving the data we need as input for the MULTIPLY platform. During its setup, it will load several data stores. A data store manages access to data that is provided locally or remotely. The DAC can be asked about the stores it provides access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Read data store aws_s2\n",
      "INFO:root:Read data store cams\n",
      "INFO:root:Read data store emulators\n",
      "INFO:root:Read data store Aster DEM\n",
      "INFO:root:Read data store MODIS Data\n",
      "INFO:root:Scanning local file system, not remote\n",
      "INFO:root:Scanning local file system, not remote\n",
      "INFO:root:Scanning local file system, not remote\n",
      "INFO:root:Scanning local file system, not remote\n",
      "INFO:root:Scanning local file system, not remote\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data store aws_s2\n",
      "Data store cams\n",
      "Data store emulators\n",
      "Data store Aster DEM\n",
      "Data store MODIS Data\n"
     ]
    }
   ],
   "source": [
    "from multiply_data_access import DataAccessComponent\n",
    "data_access_component = DataAccessComponent()\n",
    "data_access_component.show_stores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then can ask the Data Access Component what data of what type is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWS_S2_L1C',\n",
       " 'CAMS',\n",
       " 'ISO_MSI_A_EMU',\n",
       " 'ISO_MSI_B_EMU',\n",
       " 'WV_EMU',\n",
       " 'Aster DEM',\n",
       " 'MCD43A1.006']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_access_component.get_provided_data_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to perform high resolution pre-processing. For this we need S2 L1C data in the format used by AWS (AWS_S2_L1C). We also need MODIS data (from 3 days before to 3 days after the S2 observations, data type MCD43A1.006), a global DEM file (AsterDEM) and several emulators for S2 data.\n",
    "We also need to specify a spatial region of interest and start and end times. Let's suppose we are interested in the area around Barrax, Spain. We define the area by passing its coordinates in Well-Known-Text-Format (you can use https://arthur-e.github.io/Wicket/sandbox-gmaps3.html to get WKT representations of other regions of interest).\n",
    "We also define a start and ending time.\n",
    "When we have done that, we can ask the data access component for available S2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data Set:\n",
       "   Id: E:/Projects/Multiply/Data/aws_s2_l1c//AWS_S2_L1C/2017/01/16/30/S/WJ/2017/1/16/0, \n",
       "   Type: AWS_S2_L1C, \n",
       "   Start Time: 2017-01-16 10:53:55, \n",
       "   End Time: 2017-01-16 10:53:55, \n",
       "   Coverage: POLYGON((-3.000233454377241 39.75026792656397, -1.7187196513335372 39.74319619168243, -1.7365967808116474 38.754036047778804, -3.0002301960295696 38.760864456727795, -3.000233454377241 39.75026792656397)),\n",
       " Data Set:\n",
       "   Id: E:/Projects/Multiply/Data/aws_s2_l1c//AWS_S2_L1C/2017/01/19/30/S/WJ/2017/1/19/0, \n",
       "   Type: AWS_S2_L1C, \n",
       "   Start Time: 2017-01-19 11:05:33, \n",
       "   End Time: 2017-01-19 11:05:33, \n",
       "   Coverage: POLYGON((-3.000233454377241 39.75026792656397, -1.7187196513335372 39.74319619168243, -1.7365967808116474 38.754036047778804, -3.0002301960295696 38.760864456727795, -3.000233454377241 39.75026792656397))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BARRAX_ROI = \"POLYGON((-2.20397502663252 39.09868106889479,-1.9142106223355313 39.09868106889479,\" \\\n",
    "             \"-1.9142106223355313 38.94504502508093,-2.20397502663252 38.94504502508093,\" \\\n",
    "             \"-2.20397502663252 39.09868106889479))\"\n",
    "start_time = '2017-01-01'\n",
    "end_time = '2017-01-20'\n",
    "s2_data_infos = data_access_component.query(BARRAX_ROI, start_time, end_time, 'AWS_S2_L1C')\n",
    "s2_data_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has retrieved meta information about available S2 data. In particular, we can see the data coverage and the sensing date. When we are happy with the selection, let's get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Projects/Multiply/Data/aws_s2_l1c//AWS_S2_L1C/2017/01/16/30/S/WJ/2017/1/16/0',\n",
       " 'E:/Projects/Multiply/Data/aws_s2_l1c//AWS_S2_L1C/2017/01/19/30/S/WJ/2017/1/19/0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_urls = data_access_component.get_data_urls_from_data_set_meta_infos(s2_data_infos)\n",
    "s2_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get all the other data we need. First, all the emulators. We need to download them only once and can re-use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Projects/Multiply/Data/Emulators//ISO_MSI_A_EMU/isotropic_MSI_emulators_correction_xap_S2A.pkl',\n",
       " 'E:/Projects/Multiply/Data/Emulators//WV_EMU/wv_MSI_retrieval_S2A.pkl',\n",
       " 'E:/Projects/Multiply/Data/Emulators/ISO_MSI_B_EMU/isotropic_MSI_emulators_correction_xap_S2B.pkl',\n",
       " 'E:/Projects/Multiply/Data/Emulators/ISO_MSI_B_EMU/isotropic_MSI_emulators_correction_xbp_S2B.pkl',\n",
       " 'E:/Projects/Multiply/Data/Emulators/ISO_MSI_B_EMU/isotropic_MSI_emulators_correction_xcp_S2B.pkl',\n",
       " 'E:/Projects/Multiply/Data/Emulators/ISO_MSI_B_EMU/isotropic_MSI_emulators_optimization_xap_S2B.pkl',\n",
       " 'E:/Projects/Multiply/Data/Emulators/ISO_MSI_B_EMU/isotropic_MSI_emulators_optimization_xbp_S2B.pkl',\n",
       " 'E:/Projects/Multiply/Data/Emulators/ISO_MSI_B_EMU/isotropic_MSI_emulators_optimization_xcp_S2B.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emu_urls = data_access_component.get_data_urls(BARRAX_ROI, start_time, end_time, 'ISO_MSI_A_EMU,ISO_MSI_B_EMU,WV_EMU')\n",
    "emu_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the ASTER DEM URL next ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\Projects\\\\Multiply\\\\Data/DEM/aster_dem.vrt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aster_dem_url = data_access_component.get_data_urls(BARRAX_ROI, start_time, end_time, 'Aster DEM')\n",
    "aster_dem_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CAMS, we only need the data for the days for which we have S2 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Projects/Multiply/Data/CAMS/CAMS/2017/2017-01-16.nc',\n",
       " 'E:/Projects/Multiply/Data/CAMS/CAMS/2017/2017-01-19.nc']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cams_urls = data_access_component.get_data_urls(BARRAX_ROI, '2017-1-16', '2017-1-16', 'CAMS')\n",
    "cams_urls.extend(data_access_component.get_data_urls(BARRAX_ROI, '2017-1-19', '2017-1-19', 'CAMS'))\n",
    "cams_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need MODIS data from three days before the first available S2 observation up to three days after the last S2 observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading MCD43A1.A2017013.h17v05.006.2017024081921.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded MCD43A1.A2017013.h17v05.006.2017024081921.hdf\n",
      "INFO:root:Downloading MCD43A1.A2017020.h17v05.006.2017029103253.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded MCD43A1.A2017020.h17v05.006.2017029103253.hdf\n",
      "INFO:root:Downloading MCD43A1.A2017021.h17v05.006.2017032034322.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded MCD43A1.A2017021.h17v05.006.2017032034322.hdf\n",
      "INFO:root:Downloading MCD43A1.A2017022.h17v05.006.2017032100642.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded MCD43A1.A2017022.h17v05.006.2017032100642.hdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/13/MCD43A1.A2017013.h17v05.006.2017024081921.hdf',\n",
       " 'E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/14/MCD43A1.A2017014.h17v05.006.2017024085825.hdf',\n",
       " 'E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/15/MCD43A1.A2017015.h17v05.006.2017024094450.hdf',\n",
       " 'E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/16/MCD43A1.A2017016.h17v05.006.2017025102642.hdf',\n",
       " 'E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/17/MCD43A1.A2017017.h17v05.006.2017026133512.hdf',\n",
       " 'E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/18/MCD43A1.A2017018.h17v05.006.2017027113353.hdf',\n",
       " 'E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/19/MCD43A1.A2017019.h17v05.006.2017028150223.hdf',\n",
       " 'E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/20/MCD43A1.A2017020.h17v05.006.2017029103253.hdf',\n",
       " 'E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/21/MCD43A1.A2017021.h17v05.006.2017032034322.hdf',\n",
       " 'E:/Projects/Multiply/Data/MODIS/MCD43A1.006/2017/01/22/MCD43A1.A2017022.h17v05.006.2017032100642.hdf']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modis_start_time = '2017-01-13'\n",
    "modis_end_time = '2017-01-22'\n",
    "modis_urls = data_access_component.get_data_urls(BARRAX_ROI, modis_start_time, modis_end_time, 'MCD43A1.006')\n",
    "modis_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the data we need to execute the atmospheric correction. To run it, all files of a type need to be in the same folder. Let's first define a working directory as parent folder for the various data type diretories. This is supposed to be a temporary directory which later can be deleted. \n",
    "For convenience we define a method create_dir here to help us to ensure that the directories exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "working_dir = 'E:/Produkte/multiply/working_dir/'\n",
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "create_dir(working_dir)\n",
    "s2_l1c_dir = '{}/s2_l1c'.format(working_dir)\n",
    "create_dir(s2_l1c_dir)\n",
    "emus_dir = '{}/emus'.format(working_dir)\n",
    "create_dir(emus_dir)\n",
    "cams_dir = '{}/cams'.format(working_dir)\n",
    "create_dir(cams_dir)\n",
    "modis_dir = '{}/modis'.format(working_dir)\n",
    "create_dir(modis_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we do not want to actually move data around, we will place symbolic links in these folders. For this, we will use the sym linking functionality from the multiply orchestration package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiply_orchestration import create_sym_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
